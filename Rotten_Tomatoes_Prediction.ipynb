{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotten Tomatoes Review Analysis\n",
    "\n",
    "In this analysis, we will use Naive Bayes as classifier to categorize Rotten Tomatoes reviews into rotten and fresh ones. We'll find the top 10 words that predict the fresh or rotten reviews. At the end, we'll add smoothing parameter to improve the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.seterr(divide = 'ignore') \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Explore and clean the data\n",
    "First, we load the data, understand the structure and variables, summarize it, and perform data wrangling. We will mainly focus on two variables, `fresh` and `quote`, throughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('rotten-tomatoes.csv.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>Deborah Young</td>\n",
       "      <td>fresh</td>\n",
       "      <td>151568</td>\n",
       "      <td>http://www.variety.com/review/VE1117752084.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>[A] beautifully crafted and lively romp around...</td>\n",
       "      <td>2008-06-17 00:00:00</td>\n",
       "      <td>13407</td>\n",
       "      <td>Topsy-Turvy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>Amy Biancolli</td>\n",
       "      <td>rotten</td>\n",
       "      <td>427968</td>\n",
       "      <td>http://www.chron.com/disp/story.mpl/ent/movies...</td>\n",
       "      <td>Houston Chronicle</td>\n",
       "      <td>I wish the film were true to itself and its qu...</td>\n",
       "      <td>2006-09-01 00:00:00</td>\n",
       "      <td>283051883</td>\n",
       "      <td>Trust the Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Dave Kehr</td>\n",
       "      <td>fresh</td>\n",
       "      <td>31725</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>The satire may be mostly a matter of easy cont...</td>\n",
       "      <td>2009-02-03 00:00:00</td>\n",
       "      <td>18487</td>\n",
       "      <td>Ninotchka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Janet Maslin</td>\n",
       "      <td>rotten</td>\n",
       "      <td>107096</td>\n",
       "      <td>http://movies.nytimes.com/movie/review?res=9F0...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Mr. Stone tells this tale vigorously, but he h...</td>\n",
       "      <td>2004-06-05 00:00:00</td>\n",
       "      <td>14946</td>\n",
       "      <td>Heaven &amp; Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8307</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>rotten</td>\n",
       "      <td>131857</td>\n",
       "      <td>http://www.rogerebert.com/reviews/baseketball-...</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>It's not very funny and tries to buy laughs wi...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>13128</td>\n",
       "      <td>BASEketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>rotten</td>\n",
       "      <td>113321</td>\n",
       "      <td>http://www.reelviews.net/movies/h/home_holiday...</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>Aside from a few effective, low-key scenes, th...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>10161</td>\n",
       "      <td>Home for the Holidays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>Janet Maslin</td>\n",
       "      <td>fresh</td>\n",
       "      <td>88161</td>\n",
       "      <td>http://movies.nytimes.com/movie/review?res=940...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Splash may feature a heroine with fins, but it...</td>\n",
       "      <td>2003-05-20 00:00:00</td>\n",
       "      <td>12345</td>\n",
       "      <td>Splash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>Keith Simanton</td>\n",
       "      <td>fresh</td>\n",
       "      <td>119094</td>\n",
       "      <td>http://community.seattletimes.nwsource.com/arc...</td>\n",
       "      <td>Seattle Times</td>\n",
       "      <td>Face/Off is a full-blooded, movie-going experi...</td>\n",
       "      <td>2013-08-02 00:00:00</td>\n",
       "      <td>13172</td>\n",
       "      <td>Face/Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>rotten</td>\n",
       "      <td>79417</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>Misogynistic claptrap.</td>\n",
       "      <td>2006-12-13 00:00:00</td>\n",
       "      <td>11122</td>\n",
       "      <td>Kramer vs. Kramer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>Geoff Andrew</td>\n",
       "      <td>fresh</td>\n",
       "      <td>84602</td>\n",
       "      <td>http://www.timeout.com/film/reviews/76875/rock...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Learning, especially from Scorsese, in his app...</td>\n",
       "      <td>2006-02-09 00:00:00</td>\n",
       "      <td>12172</td>\n",
       "      <td>Rocky III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "13091       Deborah Young   fresh  151568   \n",
       "5114        Amy Biancolli  rotten  427968   \n",
       "3826            Dave Kehr   fresh   31725   \n",
       "2187         Janet Maslin  rotten  107096   \n",
       "8307          Roger Ebert  rotten  131857   \n",
       "356    James Berardinelli  rotten  113321   \n",
       "8479         Janet Maslin   fresh   88161   \n",
       "7492       Keith Simanton   fresh  119094   \n",
       "7893   Jonathan Rosenbaum  rotten   79417   \n",
       "9834         Geoff Andrew   fresh   84602   \n",
       "\n",
       "                                                    link        publication  \\\n",
       "13091  http://www.variety.com/review/VE1117752084.htm...            Variety   \n",
       "5114   http://www.chron.com/disp/story.mpl/ent/movies...  Houston Chronicle   \n",
       "3826   http://onfilm.chicagoreader.com/movies/capsule...     Chicago Reader   \n",
       "2187   http://movies.nytimes.com/movie/review?res=9F0...     New York Times   \n",
       "8307   http://www.rogerebert.com/reviews/baseketball-...  Chicago Sun-Times   \n",
       "356    http://www.reelviews.net/movies/h/home_holiday...          ReelViews   \n",
       "8479   http://movies.nytimes.com/movie/review?res=940...     New York Times   \n",
       "7492   http://community.seattletimes.nwsource.com/arc...      Seattle Times   \n",
       "7893   http://onfilm.chicagoreader.com/movies/capsule...     Chicago Reader   \n",
       "9834   http://www.timeout.com/film/reviews/76875/rock...           Time Out   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "13091  [A] beautifully crafted and lively romp around...  2008-06-17 00:00:00   \n",
       "5114   I wish the film were true to itself and its qu...  2006-09-01 00:00:00   \n",
       "3826   The satire may be mostly a matter of easy cont...  2009-02-03 00:00:00   \n",
       "2187   Mr. Stone tells this tale vigorously, but he h...  2004-06-05 00:00:00   \n",
       "8307   It's not very funny and tries to buy laughs wi...  2000-01-01 00:00:00   \n",
       "356    Aside from a few effective, low-key scenes, th...  2000-01-01 00:00:00   \n",
       "8479   Splash may feature a heroine with fins, but it...  2003-05-20 00:00:00   \n",
       "7492   Face/Off is a full-blooded, movie-going experi...  2013-08-02 00:00:00   \n",
       "7893                              Misogynistic claptrap.  2006-12-13 00:00:00   \n",
       "9834   Learning, especially from Scorsese, in his app...  2006-02-09 00:00:00   \n",
       "\n",
       "            rtid                  title  \n",
       "13091      13407            Topsy-Turvy  \n",
       "5114   283051883          Trust the Man  \n",
       "3826       18487              Ninotchka  \n",
       "2187       14946         Heaven & Earth  \n",
       "8307       13128            BASEketball  \n",
       "356        10161  Home for the Holidays  \n",
       "8479       12345                 Splash  \n",
       "7492       13172               Face/Off  \n",
       "7893       11122      Kramer vs. Kramer  \n",
       "9834       12172              Rocky III  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['critic', 'fresh', 'imdb', 'link', 'publication', 'quote',\n",
       "       'review_date', 'rtid', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Summary of the data-------\n",
      "1. There are 23 non-missing values in fresh.\n",
      "2. There are three types of value in fresh/rotten evaluations. The corresponding counts and percentages are:\n",
      "        counts  percentages\n",
      "fresh     8389     0.624089\n",
      "rotten    5030     0.374200\n",
      "none        23     0.001711 \n",
      "\n",
      "3. There are 0 zero-length in quote, and 0 quotes with only whitespace.\n",
      "4. Length of quotes: minimum= 4 ,maximum= 256 ,and average= 121.\n",
      "5. There are 596 duplicate reviews.\n"
     ]
    }
   ],
   "source": [
    "fresh_evaluations = pd.DataFrame(data.fresh.value_counts()).rename(columns={'fresh':'counts'})\n",
    "fresh_evaluations['percentages']=fresh_evaluations['counts']/sum(fresh_evaluations['counts'])\n",
    "\n",
    "print('------Summary of the data-------')\n",
    "print('1. There are %i non-missing values in fresh.' %data[data['fresh']=='none'].fresh.count())\n",
    "print('2. There are three types of value in fresh/rotten evaluations. The corresponding counts and percentages are:')\n",
    "print(fresh_evaluations, '\\n')\n",
    "print('3. There are %i zero-length in quote,' %data[data.quote.str.len()==0].quote.count(), 'and %i quotes with only whitespace.' %data[data.quote==' '].quote.count())\n",
    "print('4. Length of quotes: minimum= %i' %min(data.quote.str.len()), ',maximum= %i' %max(data.quote.str.len()), ',and average= %i.' %data.quote.str.len().mean())\n",
    "print('5. There are %i duplicate reviews.' %len(data[data.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate data\n",
    "data = data[~data.duplicated()]\n",
    "#remove none in fresh variable\n",
    "data = data[data['fresh']!='none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Naive Bayes\n",
    "In the second part, we implement the Naive Bayes classifier and convert the data into bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# define vectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# vectorize your data. Note: this creates a sparce matrix,\n",
    "# use .toarray() if you want a dense matrix.\n",
    "X = vectorizer.fit_transform(data.quote.values)\n",
    "X_a = X.toarray()\n",
    "\n",
    "# actual words\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "# rating\n",
    "y = data.fresh.values\n",
    "\n",
    "# quote\n",
    "quote = data['quote']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model better, we split our data into three sets: training, validation, and testing data. We keep 20% of the data as test data and split the rest 80% into 80% training and 20% testing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, q_train, q_test = train_test_split(X_a, y, quote, test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid, q_train, q_valid = train_test_split(X_train, y_train, q_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start to work on our training data.  \n",
    "In the following part, we compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F) `lpr_F`, and log Pr(R) `lpr_R`.  \n",
    "These probabilities are based on the values of fresh alone, not on the words the quotes contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability for Fresh is -0.4766059273453062 , for Rotten is -0.9699213761044944\n"
     ]
    }
   ],
   "source": [
    "# calculate total numbers of fresh and rotten reviews\n",
    "fresh = np.unique(y_train, return_counts=True)[1][0]\n",
    "rotten = np.unique(y_train, return_counts=True)[1][1]\n",
    "\n",
    "# log probability of Fresh review\n",
    "lpr_F = math.log(fresh/len(y_train))\n",
    "# log probability of rotten review\n",
    "lpr_R = math.log(rotten/len(y_train))\n",
    "\n",
    "print('The log probability for Fresh is', lpr_F, ', for Rotten is', lpr_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word w, we compute log Pr(w|F) `lpr_wF` and log Pr(w|R) `lpr_wR`, the (log) probability that the word is present in a fresh/rotten review. These probabilities will be calculated from counts of how many times these words are present for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create blank array to store the fresh and rotten quotes\n",
    "fresh_wcount = np.zeros(len(X_train[0]))\n",
    "rotten_wcount = np.zeros(len(X_train[0]))\n",
    "\n",
    "# calculate frequency of individual word in fresh and rotten reviews\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]=='fresh':\n",
    "        fresh_wcount = fresh_wcount + X_train[i]\n",
    "    else:\n",
    "        rotten_wcount = rotten_wcount + X_train[i]\n",
    "\n",
    "# log probability of word given Fresh review\n",
    "lpr_wF = np.log(fresh_wcount/fresh)\n",
    "# log probability of word given rotten review\n",
    "lpr_wR = np.log(rotten_wcount/rotten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the four probabilities, we've fitted our Naive Bayes model. For the next step, we use the model to predict the reviews using validation data. We compute the log-likelihood of being a fresh, `l_F`, or rotten, `l_R`, review for each quote in the validation dataset.  \n",
    "We create two functions to make the calculation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_calF(X_valid, lpr_wF, lpr_F):\n",
    "    \"\"\"Take in an array and output the log-likelihood of Fresh\"\"\"\n",
    "    temp_pr_wF = X_valid*lpr_wF\n",
    "    # change nan to 0\n",
    "    temp_pr_wF = np.nan_to_num(temp_pr_wF)\n",
    "    # change -0 to 0\n",
    "    temp_pr_wF = np.where(np.nan_to_num(temp_pr_wF)==0, 0, temp_pr_wF)\n",
    "    total = lpr_F + sum(temp_pr_wF)\n",
    "    return total\n",
    "\n",
    "def log_calR(X_valid, lpr_wR, lpr_R):\n",
    "    \"\"\"Take in an array and output the log-likelihood of Rotten\"\"\"\n",
    "    temp_pr_wR = X_valid*lpr_wR\n",
    "    # change nan to 0\n",
    "    temp_pr_wR = np.nan_to_num(temp_pr_wR)\n",
    "    # change -0 to 0\n",
    "    temp_pr_wR = np.where(np.nan_to_num(temp_pr_wR)==0, 0, temp_pr_wR)\n",
    "    total = lpr_R + sum(temp_pr_wR)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fuctions to the data and calculate the log-likelihood of the quote being a Fresh or Rotten reviews \n",
    "l_F = np.apply_along_axis(log_calF, 1, X_valid, lpr_wF, lpr_F)\n",
    "l_R = np.apply_along_axis(log_calR, 1, X_valid, lpr_wR, lpr_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compare the probabilities of being fresh and rotten so as to see the quote is predicted as fresh or rotten review. For example, if the probability of being a fresh quote is bigger than the probability of being a rotten quote, then the quote is predicted as fresh.  \n",
    "*We'll ignore the situation where the probabilities are the same for now. (i.e. `l_F` = `l_R`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_or_R(array):\n",
    "    \"\"\"Take in a quote and output whether the quote is predicted as Fresh or Rotten based on the log-likelihood.\n",
    "    If the log-likelihood of Fresh and Rotten are the same, return Rotten\"\"\"\n",
    "    array = np.where(array == True, 'fresh', 'rotten')\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 912 quotes with the same probabilities of Fresh and Rotten. We'll ignore that first.\n",
      "Confusion matrix:\n",
      " [[614 660]\n",
      " [203 575]]\n",
      "Accuracy = 0.5794346978557505\n"
     ]
    }
   ],
   "source": [
    "# apply function to the data and return a prediction array\n",
    "predicted = np.apply_along_axis(F_or_R, 0, l_F > l_R)\n",
    "\n",
    "# print out how many cases with the same probabilities\n",
    "print('There are %i quotes with the same probabilities of Fresh and Rotten. We\\'ll ignore that first.' %sum(l_F==l_R))\n",
    "\n",
    "# use confusion matrix and accuracy to show the performance of the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_valid, predicted))\n",
    "tn, fp, fn, tp = confusion_matrix(y_valid, predicted).ravel()\n",
    "accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
    "print(\"Accuracy =\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy isn't high. We can improve the performance of the model in part 4 by adding smoothing parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Interpretation\n",
    "In this part, we'll interpret our prediction and try to find the top 10 words that best predict fresh and rotten reviews. In order to get a better and more informative result, we will focus on words that are reasonably frequent, more frequent than 30 times in the data.\n",
    "### Top 10 words in Fresh and Rotten reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out words with frequency less than 30 times\n",
    "frequent_F = fresh_wcount * np.where((fresh_wcount >30)==True,1,0)\n",
    "frequent_R = rotten_wcount * np.where((rotten_wcount >30)==True,1,0)\n",
    "\n",
    "# log probability of Fresh review of frequent word\n",
    "lpr_fwF = np.log(frequent_F/fresh)\n",
    "# log probability of rotten review of frequent word\n",
    "lpr_fwR = np.log(frequent_R/rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words to predict Fresh reviews: ['the', 'and', 'of', 'is', 'to', 'it', 'in', 'that', 'with', 'film']\n",
      "Top 10 words to predict Rotten reviews: ['the', 'and', 'of', 'to', 'is', 'it', 'in', 'that', 'but', 'this']\n"
     ]
    }
   ],
   "source": [
    "# find top 10 words of fresh and rotten reviews\n",
    "F_top10 = list(words[i] for i in np.argsort(lpr_fwF))[::-1][:10]\n",
    "R_top10 = list(words[i] for i in np.argsort(lpr_fwR))[::-1][:10]\n",
    "print('Top 10 words to predict Fresh reviews:',F_top10)\n",
    "print('Top 10 words to predict Rotten reviews:',R_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the top 10 words include many stop words and are not informative. We use `nltk` to remove stop words and find the top 10 words for Fresh and Rotten reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/serenalin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(array): \n",
    "    nostop = []\n",
    "    j = 0\n",
    "    sorted_fw = list(words[i] for i in np.argsort(array))[::-1]\n",
    "    while len(nostop) <= 10:\n",
    "        temp = sorted_fw[j]\n",
    "        if temp not in stop_words:\n",
    "            nostop.append(temp)\n",
    "        j += 1\n",
    "    return nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words to predict Fresh reviews (without stop words):\n",
      " ['film', 'movie', 'one', 'best', 'good', 'story', 'like', 'time', 'well', 'comedy', 'director']\n",
      "Top 10 words to predict Rotten reviews (without stop words):\n",
      " ['movie', 'film', 'like', 'one', 'much', 'story', 'even', 'comedy', 'director', 'good', 'little']\n"
     ]
    }
   ],
   "source": [
    "F_top10_nostop = remove_stopwords(lpr_fwF)\n",
    "R_top10_nostop = remove_stopwords(lpr_fwR)\n",
    "print('Top 10 words to predict Fresh reviews (without stop words):\\n',F_top10_nostop)\n",
    "print('Top 10 words to predict Rotten reviews (without stop words):\\n',R_top10_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we remove stop words, the predictive words for Fresh and Rotten reviews still look very similar. Therefore, we use part-of-speech tagging to identify the top 10 adjective for Fresh and Rotten reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def filter_adj(array):\n",
    "    adj = []\n",
    "    j = 0\n",
    "    sorted_list = list(words[i] for i in np.argsort(array))[::-1]\n",
    "    while len(adj) <= 10:\n",
    "        word = sorted_list[j]\n",
    "        tag = nltk.pos_tag([word])[0][1]\n",
    "        if tag in ('JJ','JJR','JJS') and word not in stop_words:\n",
    "            adj.append(word)\n",
    "        j += 1\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 adjective words to predict Fresh reviews (without stop words):\n",
      " ['best', 'good', 'much', 'great', 'new', 'american', 'little', 'old', 'many', 'big', 'high']\n",
      "Top 10 adjective words to predict Rotten reviews (without stop words):\n",
      " ['much', 'good', 'little', 'bad', 'many', 'best', 'hard', 'new', 'real', 'comic', 'old']\n"
     ]
    }
   ],
   "source": [
    "F_top10_adj = filter_adj(lpr_fwF)\n",
    "R_top10_adj = filter_adj(lpr_fwR)\n",
    "print('Top 10 adjective words to predict Fresh reviews (without stop words):\\n',F_top10_adj)\n",
    "print('Top 10 adjective words to predict Rotten reviews (without stop words):\\n',R_top10_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassified quotes\n",
    "Next, we'll look into some quotes we misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Predicted: rotten \tActual: fresh\n",
      "If [The Whole Nine Yards] should not have worked, then the sequel definitely shouldn't work, either. But, once again, it kind of does. \n",
      "\n",
      "2. Predicted: rotten \tActual: fresh\n",
      "It's the rare kind of movie that makes too much seem like a good idea. \n",
      "\n",
      "3. Predicted: rotten \tActual: fresh\n",
      "A reasonably enjoyable (for those captivated by this sort of thing) black comedy/noir thriller. \n",
      "\n",
      "4. Predicted: fresh \tActual: rotten\n",
      "Ostensibly about the banality of youthful evil, Kids is simply about its own banality. \n",
      "\n",
      "5. Predicted: rotten \tActual: fresh\n",
      "What gives the film its jolt of urgency is its New Orleans setting. Deja Vu is the first major movie to be shot there since the city's devastation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "mis_q = q_valid[~(predicted == y_valid)]\n",
    "mis_p = predicted[~(predicted == y_valid)]\n",
    "mis_y = y_valid[~(predicted == y_valid)]\n",
    "mis_len = len(mis_q)\n",
    "# set seed and randomly pick 5 out of the misclassified quotes\n",
    "np.random.seed(20)\n",
    "index = np.random.choice(mis_len,5,replace=False)\n",
    "\n",
    "for i in index:\n",
    "    print('%i.' %count, 'Predicted:', mis_p[i], '\\tActual:', mis_y[i])\n",
    "    print(mis_q.iloc[i],'\\n')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 NB with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, alpha):\n",
    "    fresh = np.unique(y_train, return_counts=True)[1][0]\n",
    "    rotten = np.unique(y_train, return_counts=True)[1][1]\n",
    "\n",
    "    # log probability of Fresh review\n",
    "    lpr_F = math.log((fresh+alpha)/(len(y_train)+alpha*2))\n",
    "    # log probability of rotten review\n",
    "    lpr_R = math.log((rotten+alpha)/(len(y_train)+alpha*2))\n",
    "    \n",
    "    # create blank array to store the value\n",
    "    fresh_wcount = np.zeros(len(X_train[0]))\n",
    "    rotten_wcount = np.zeros(len(X_train[0]))\n",
    "\n",
    "    # calculate frequency of individual word in fresh and rotten reviews\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i]=='fresh':\n",
    "            fresh_wcount = fresh_wcount + X_train[i]\n",
    "        else:\n",
    "            rotten_wcount = rotten_wcount + X_train[i]\n",
    "    \n",
    "    # log probability of Fresh review\n",
    "    lpr_wF = np.log((fresh_wcount+alpha)/(fresh+alpha))\n",
    "    # log probability of rotten review\n",
    "    lpr_wR = np.log((rotten_wcount+alpha)/(rotten+alpha))\n",
    "    return lpr_F, lpr_R, lpr_wF, lpr_wR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_valid, y_valid, fit_list):\n",
    "    lpr_F = fit_list[0]\n",
    "    lpr_R = fit_list[1]\n",
    "    lpr_wF = fit_list[2]\n",
    "    lpr_wR = fit_list[3]\n",
    "    l_F = np.apply_along_axis(log_calF, 1, X_valid, lpr_wF, lpr_F)\n",
    "    l_R = np.apply_along_axis(log_calR, 1, X_valid, lpr_wR, lpr_R)\n",
    "    predicted = np.apply_along_axis(F_or_R, 0, l_F > l_R)\n",
    "    matrix = confusion_matrix(y_valid, predicted)\n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
    "    return matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv(k, fit, predict, X, y, alpha):\n",
    "    X_len = len(X)\n",
    "    # create a list of indices to shuffle the data\n",
    "    i = np.random.choice(X_len,X_len, replace=False)\n",
    "    XX = X[i]\n",
    "    yy = y[i]\n",
    "    # create a k-fold function\n",
    "    kf = KFold(n_splits=k)\n",
    "    # creat empty lists to store the metrics\n",
    "    scores = []\n",
    "    fscore = []\n",
    "    # split the training data into k section, and work on one section at a time\n",
    "    for train_index, validate_index in kf.split(XX):\n",
    "        X_train, X_validate = XX[train_index], XX[validate_index]\n",
    "        y_train, y_validate = yy[train_index], yy[validate_index]\n",
    "        # fit the model\n",
    "        after_fit = fit(X_train, y_train, alpha)\n",
    "        # calculate accuracy to measure the performance\n",
    "        scores.append(predict(X_validate, y_validate, after_fit)[1])\n",
    "    return round(np.mean(scores),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 1.000000, the accuracy of the model after 5 fold cross validation is 0.738000\n",
      "With alpha = 0.100000, the accuracy of the model after 5 fold cross validation is 0.742700\n",
      "With alpha = 0.010000, the accuracy of the model after 5 fold cross validation is 0.726200\n",
      "\n",
      "When alpha = 0.100000, the model has the best performance with accuracy = 0.742700\n"
     ]
    }
   ],
   "source": [
    "best_alpha = 0\n",
    "best_accuracy = 0\n",
    "k=5\n",
    "power = 0\n",
    "stop = 1\n",
    "while stop >= best_accuracy:\n",
    "    alpha = pow(10,power)\n",
    "    result = cv(k, fit, predict, X_a, y, alpha)\n",
    "    stop = result\n",
    "    print('With alpha = %f,' %alpha, 'the accuracy of the model after %i' %k, 'fold cross validation is %f' %result)\n",
    "    if result >= best_accuracy:\n",
    "        best_alpha = alpha\n",
    "        best_accuracy = result\n",
    "    power -=1\n",
    "print('\\nWhen alpha = %f,' %best_alpha, 'the model has the best performance with accuracy = %f' %best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
